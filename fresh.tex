\documentclass[12pt]{article}
\usepackage[parfill]{parskip}
\usepackage{amsmath}
\linespread{1.5}

\begin{document}

\section{Introduction}

Perturbation theory has its roots in celestial mechanics and aerodynamics. There
are two particularly interesting victories the field has seen. The first was the
discovery of Neptune, and the second is the theoretical foundation for
aerodynamics. We will give a short account of these in the history section.

The promise of perturbation theory is that it allows us to solve a
larger class of problems than we could otherwise with analytical methods. It
does this by giving us approximate, but rigorous, solutions. In this article we
will guide the reader from some a very simple and familiar example, a quadratic
equation, all the way to a useful research example in system biology: the total
quasi steady state in enzyme kinetics.

The article has been written with the goal that any student with a basic
understanding of calculus, differential equations and linear algebra will be
able to follow along. All the relevant biology and perturbation theory will be
explained as we go along.

TODO: Write a subsection on the history of perturbation theory.

\section{A regular perturbation}

We are going to start with probably the simplest non-trivial example imaginable:
a quadratic equation.

\begin{equation}
x^2 - 2x + \epsilon = 0
\end{equation}

We know how to solve this analytically. The roots of the equation are $x = 1 +
\sqrt{1 - \epsilon}$ and $x = 1 - \sqrt{1 - \epsilon}$.

The case we are interested in is the one where $\epsilon$ is very small. In this
case, we can see that setting $\epsilon=0$ produces the roots $x=0$ and $x=2$
respectively. In fact, for any given small $\epsilon$ we notice that solution
changes very little. In that sense it's a very "boring" and predictable problem.

How can we make this observation more rigorous? One way is to rewrite the part
of the solution containing $\epsilon$ as a Taylor series. Recall that a Taylor
series for a function $f(x)$ around a looks like follows.

\begin{equation}
f(x) = \sum_{n=0}^{\infty} \frac{f^{n}(a)}{n!} (x-a)^n
\end{equation}

The Taylor series for $f(\epsilon) = (1 - \epsilon)^{1/2}$ around 0 is thus.

\begin{equation}
\sqrt{1 - \epsilon} = 1 - \frac{\epsilon}{2} - \frac{\epsilon^2}{8} + O(\epsilon^3)
\end{equation}

If we take the limit of this as $\epsilon \to 0$, it's obvious that our
intuition is correct. That is, a small change in epsilon only brings about a
small change in the solution.

\begin{align*}
x_1 &= \frac{\epsilon}{2} + \frac{\epsilon^2}{8} + O(\epsilon^3), \\
x_2 &= 2 - \frac{\epsilon}{2} - \frac{\epsilon^2}{8} + O(\epsilon^3)
\end{align*}

What is the point of all this? We said in the beginning that perturbation theory
allows us to solve a larger class of problems, but what we have done so far
hasn't given any indication of that being true. After all, we already have an
analytical formula for the quadratic equation.

Let's start over, but this time let's assume we don't have the quadratic formula
at our disposal. We will outline a method which would allow us to get arbitrarly
good approximations for polynomials of any degree.

Let's assume the solution of (1) can be expressed on the form of a power series
of $\epsilon$.

\begin{equation}
\sum_0^{\infty} a_k \epsilon^k = a_0 + a_1 \epsilon + a_2 \epsilon^2 + ...
\end{equation}

We will now insert this power series into (1), and then expand that expression
in terms of powers of $\epsilon$. We only have to do this for the first few
terms of the power series, as we will see in the end. If we want to we can
always add more terms and get a more accurate approximation.

\begin{equation}
(a_0 + a_1 \epsilon + a_2 \epsilon^2 + ...)^2 - 2(a_0 + a_1 \epsilon + a_2
\epsilon^2 + ...) + \epsilon = 0
\end{equation}

We expand the expression using Big-Oh algebra. For example, $(a_0 + a_1 \epsilon
+ a_2 \epsilon^2)^2 = a_0^2 + 2 a_0 a_1 \epsilon + (a_1^2 + 2 a_0 a_2) \epsilon^2 + O(\epsilon^3)$.

The whole expression becomes the following.

\begin{equation}
a_0^2 - 2 a_0 + (2 a_0 a_1 - 2 a_1 + 1)\epsilon + (a_1^2 + 2 a_0 a_2 - 2 a_2)
\epsilon^2 = O(\epsilon^3), \epsilon \to 0
\end{equation}

Now we turn the problem of determining the coefficients $a_0$, $a_1$ etc. Since
$\epsilon$ is a variable here rather than a parameter, we see that the
coefficients before each power of $\epsilon$ separately all have to be equal to
zero. For example, $a_0^2 - 2 a_0 = 0$ when $\epsilon \to 0$, and if we remove
that part and divide the rest by $\epsilon$ we get the same for the next
coefficient, etc. We thus get the following system of equations for solving the
coefficients.

\begin{align*}
a_0^2 - 2 a_0 &=0, \\
2 a_0 a_1 - 2 a_1 + 1 &= 0, \\
a_1^2 + 2 a_0 a_2 - 2 a_2 &= 0
\end{align*}

Solving these equations in turn gives us $a_0 = 0$ or $a_0 = 2$. For $a_0 = 0$ we
have $a_1 = \frac{1}{2}$ and $a_2 = \frac{1}{8}$. For $a_0 = 2$ we have $a_1 = -
\frac{1}{2}$ and $a_2 = - \frac{1}{8}$.

We said at the beginning that we assume the solution is on the form of a power
series of $\epsilon$. We have two options for the coefficients, and these
corresponds to the two approximate solutions.

\begin{align*}
x_1 &= \frac{1}{2} \epsilon + \frac{1}{8} \epsilon^2 + O(\epsilon^3), \\
x_2 &= 2 - \frac{1}{2} \epsilon - \frac{1}{8} \epsilon^2 + O(\epsilon^3)
\end{align*}

This corresponds well to our previous solution, without the use of the
quadratica formula. We have thus found a general method for finding approximate
solutions to polynomials of any degree with a small parameter $\epsilon$.

\section{A singular perturbation}

In the last section we dealt with a so called regular problem. In this section
we will deal with a singular perturbation problem. What is the difference? In a
singular perturbation problem, the small $\epsilon$ \textit{matters} for the
solution. In general, singular problems are generally interesting precisely
because their solutions can change a lot with just a small change in
circumstances.

As before, we will use a quadratic equation to illustrate how it works.

\begin{equation}
\epsilon x^2 - 2 x + 1 = 0
\end{equation}

As before, we take $\epsilon$ to be a very small number. This equation has the
following solutions.

\begin{equation}
x_1 = \frac{1 + \sqrt{1 - \epsilon}}{\epsilon}, \\
x_2 = \frac{1 - \sqrt{1 - \epsilon}}{\epsilon}.
\end{equation}

The first thing we notice is that even though $\epsilon$ is very small, we can't
set it to zero. If we were to do it in (8), we would only get a one degree
polynomial. The fact that we are losing solutions is a qualitative change, and
is indicative that we are dealing with a singular perturbation problem.

We can re-use the Taylor expansion of $\sqrt{1 - \epsilon}$ from (3), and we
would get that the solutions of our equation are.

TODO: Provide Taylor expansion.

\begin{equation}
x_1 = \frac{1 + \sqrt{1 - \epsilon}}{\epsilon}, \\
x_2 = \frac{1 - \sqrt{1 - \epsilon}}{\epsilon}.
\end{equation}

We have a problem here. As $\epsilon \to 0$, the root $x_2 \to \infty$. Is this
correct? Let's use the same method a we did before. We assume the solution can
be expressed in the form of a power series of $\epsilon$. Inserting this in our
equation gives us the following.

\begin{equation}
\epsilon (a_0 + \epsilon a_1 + ...)^2 - 2(a_0 + \epsilon a_1 + \epsilon^2 a_2 +
...) + 1 = 0
\end{equation}

which gets expanded into.

\begin{equation}
(- 2 a_0 + 1) + (2 a_1) \epsilon + (a_0 + a_2) \epsilon^2 + O(\epsilon^3)
\end{equation}

and leads to.

\begin{align*}
- 2 a_0 + 1 &= 0, \\
2 a_1 &= 0, \\
a_0 + a_2 &= 0
\end{align*}

$a_0$ = \frac{1}{2}$, $a_1=0$, $a_2= - \frac{1}{2}$,  but this gives us only one
of the roots, $x_1$.

TODO: Check algebra. Is this correct?

\begin{equation}
x_1 = \frac{1}{2} - \frac{1}{2} \epsilon^2 + O(\epsilon^3)
\end{equation}

That's only one solution though. By the Fundamental Theorem of Algebra, we would
expect to see two solutions. What happened with the other root? We missed it
because it's not on the form of a perturbation series. We got a hint of this
when we saw the Taylor expansion of the root, but remember that we aren't
supposed to use that. So what do we do?
  
TODO: Explain how this specific change of variable is motivated.

The key here is that we can do a change in variable to turn the problem into a
regular perturbation problem.

Exactly how we do this differ from problem to
problem, but in this case we are going to call $\overline{x} = \epsilon x$.

Our original equation (8) then becomes.

TODO: Something is wrong here. Read more.

\section{ODE and boundary theory}

We are now going to look at at differential equation.

\begin{equation}
\epsilon y'' + 2 y' + y, y(0)=0, y(1)=1, 0 <x < 1
\end{equation}

\section{Total Quasi Steady State}

\end{document}
