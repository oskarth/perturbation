\documentclass[12pt]{report}

\usepackage{hyperref}

\newcommand{\link}[2]{\href{#1}{#2}}

% \usepackage[utf8]{inputenc}
% \usepackage{mathtools}
\usepackage[parfill]{parskip} % line skip paragraphs
\linespread{1.5} % linespacing 1.5

\begin{document}

\bibliographystyle{plain}

\title{Singular Pertubation Theory and TQSSA}
\author{Oskar Thor\'{e}n}

\maketitle

\chapter{Singular perturbation theory}

\section{History and introduction}

\textit{It causeth my head to ache} -- Newton on the orbits of the moon. Three
body problem. Discovery Neptunus, but also Vulcan. Poincare and Prandtl.

Many phenomena can be modelled by ODEs, but only a subset of ODEs can be solved
exactly. We need approximate solutions that are justified in a rigorous manner.

This text is heavily inspired by two source. The first is \textit{A first look
at Perturbation Theory} by Simmonds. The other is \textit{Applied mathematics
in...} by Lin and Segel.

\section{Simple regular perturbation}

Let's start with a simple quadratic equation.

\begin{equation}
  z^2 - 2z + \epsilon
\end{equation}


For small $\epsilon$, how does the solution change? The first thought we might
have is that we simply set $\epsilon$ to zero. If we do that we get two
solutions, $z_1 = 2$ and $z_2 = 0$. In this case, since we know the exact
solution to the full equationis $z = 1 \pm \sqrt{1-\epsilon}$, it's easy to see
that changing $\epsilon$ a bit only changes the solution a bit. The solutions to
the equation will be around $0$ and $2$.

When we say that $\epsilon$ is small, we mean something like $0 < \epsilon
\ll 1$. The symbol $\ll$ means that the limit of $\epsilon$ over unity
approaches $0$.

One way to do this more rigorously is to expand $\sqrt{1-\epsilon}$ part as a
Taylor series around $\epsilon = 0$. In this case, we could've used a binominal series expansion as
well.

$\sqrt{1 - \epsilon}$ = $1 - \frac 1 2 \epsilon - \frac 1 8 \epsilon^2 +
O(\epsilon^3)$

The Big-oh notation is just a way to sweep irrelevant arithmetic details under
the rug. What it's saying is that the following terms won't grow faster than on
the order of $\epsilon^2$ (which, as $\epsilon$ is close to zero, is essentially
insignificant).

Using that Taylor expansion in our original solution, and performing some basic
Big-Oh algebra, we get $z_1 = \frac 1 2 \epsilon + O(\epsilon^2)$ and $z_2 = 2 -
\frac 1 2 \epsilon + O(\epsilon^2)$. Here I'm content with the $O(\epsilon^2)$
term at the end, as more details aren't necessary for our current purposes.

What does this tell us? What've established is a way to get successively better
approximations to the solutions, given that $\epsilon$ is very small. The
reduced equation corresponds to setting $\epsilon$ to $0$. This is called
something like the 0th order perturbation. If we want the first order
perturbation, we get the solutions as seen above. You can imagine
substituting $\epsilon$ for a very small number, and you have some idea for how
the solutions behaves.

Let's assume we don't know exact solution to this quadratic equation. Instead
we'll assume that we can express the solution using a perturbation series, that
is every root of $P_\epsilon(z) = z^2 - 2z + \epsilon$ has a perturbation
expansion for some N. A perturbation expansion is defined as follows:

\begin{equation}
  z(\epsilon) = a_0 + a_1 \epsilon + a_2 \epsilon^2 + ...  + R^{n+1}, R^{n+1} = O(\epsilon^{N+1})
\end{equation}

How do we go about doing this? What we want to do is to determine the
coefficients $a_0$, $a_1$ etc. We do this by writing

$$P_\epsilon(z(\epsilon)) = P_\epsilon(a_0 + a_1\epsilon + ... +
O(\epsilon^{N+1})) = (a_0 + a_1\epsilon + ...)^2 - 2(a_0 + a1_\epsilon + ...) +
\epsilon = 0$$

It's identically equal as $\epsilon \to 0$. Now we simply
collect the $\epsilon$ terms and do some Big-oh algebra to put it in the
required form for some N.

For example, if N=1 we have $z(\epsilon) = a_0 + a_1\epsilon + O(\epsilon^2)$
and $z^2(\epsilon) = ... = a_0^2 + 2 a_0 a_1 \epsilon + O(\epsilon^2)$.

Skipping over a lot of steps here.

We finally get, for $N=2$, something like

$$P_\epsilon(z_\epsilon) = (a_0^2 - 2_{a_0}) + (2 a_0 a_1 - 2 a_1 +1)\epsilon + (a_1^2 + 2 a_0 a_2 -
2 a_2)\epsilon^2 + O(\epsilon^3) = 0$$

$(a_0^2 - 2_{a_0}) = 0$, since expression must be identically equal to zero as
$\epsilon \to 0$. If $P_\epsilon(z(\epsilon)) = 0$ for small $\epsilon$... (skipping this part).

Fundamental theorem of perturbation theory says that if we have such an
expansion, identically equal to 0, for $\epsilon$ sufficiently small, and all
the coefficients are independent of $\epsilon$ (i.e. factored out), then the
coefficients $A_0 = A_1 = ... = A_N = 0$. What this means for us that we get a
system of equations consisting of the following two equations:

$$ a_0^2 - 2_{a_0} = 0$$
$$ 2 a_0 a_1 - 2 a_1 +1 = 0 $$
$$ a_1^2 + 2 a_0 a_2 -2 a_2 = 0$$

We simple solve this like we normall would. $a_0 = 0$ or $a_0 = 2$. If we pick
the first solution, we get $a_1=\frac 1 2$, and that gives $a_2 = \frac 1 8$.

This gives us the same perturbation series as when we knew the solution of the
quadratic equation, without actually knowing the exact solution. That is, we
could do the same on any polynomial of any degree, giving us an approximate
solution without knowing an exact one.


- Write down definition of Big Oh

\section{Simple singular perturbation}

Let's look at a slightly more interesting example.

\begin{equation}
  \epsilon z^2 - 2z + 1
\end{equation}

In this example, assuming we are aware of the quadratic equation for
polynomials, we have $z = \frac{(1 \pm \sqrt{1-\epsilon})}{\epsilon}$. As
$\epsilon \to 0$ we have a singularity. If we don't know the exact solution, and
simply try to set $\epsilon=$, we note that we are removing one of the roots. This is indicative of a singular perturbation problem - we are missing something when we remove the error term.

If we proceed as we did in the last section, assuming we don't know the exact
solution, we get an expression of one of the roots, but we don't get the other
one. Why not? Because the exact root (if we Taylor expand the exact solution,
starts with $\frac 2 \epsilon$, which is not on the form of a perturbation
series) [This is a messy paragraph].

If we don't know the exact solution, we can still get that the missing root
$z_2(\epsilon)$ approaches $\infty$. We know that there must be two roots, since
the polynomial is of degree two. We got

$$Q_\epsilon(z) = \epsilon z^2 - 2z +1 = \epsilon[z - z_1(\epsilon)][z -
z_2(\epsilon)] = \epsilon z^2 - \epsilon [z_1(\epsilon) + z_2(\epsilon)]z +
\epsilon z_1(\epsilon)z_2(\epsilon)$$

If $z=0$, we have $1 = \epsilon z_1(\epsilon) z_2(\epsilon)$, so as $\epsilon
\to 0$, $z_2 \to \infty$ (inverse of $\epsilon$), since the other root approaches a finite value.

We can make a simplification here: when $z_2(\epsilon)$ is large, $-2
z_2(\epsilon) + 1 \sim -2 z_2(\epsilon)$ ($f \sim g$ means f asymptotic to g as
$\epsilon$ approaches 0, $\frac f g \to 1$).

We then have $z_2 \sim \epsilon z_2^2 - 2 z_2$ leads to $z_2 \sim \frac 2 \epsilon$
(sloppy writing). Just a heuristic, not rigorous argument, but it leads to the
conjecture:

$$\epsilon z_2(\epsilon) \sim b_0 \neq 0$$

$b_0 = 2$ doesn't matter, just that it's $\neq 0$. This suggest a change of
variable:

$$\epsilon z (\epsilon) = \omega (\epsilon)$$

A lot of notation missing. Essence is that we turn a singular behavior, with the
change of a varible, and reduce it into a regular perturbation problem.

$$\epsilon Q(\frac \omega \epsilon) = \omega^2 - 2\omega + \epsilon$$

Now we get essentially the same as before with the regular problem.

$$\omega_2(\epsilon) = 2 - \frac 1 2 \epsilon + O(\epsilon^2)$$

which gives

$$z_2(\epsilon) = \frac 2 \epsilon - \frac 1 2 + O(\epsilon)$$

We have thus found an approximate expression of the other root, by turning the
singular problem into a regular one.

Procedure for this:

1. Substitute
2. Expand
3. Collect
4. Substitute original IC/BC
5. ...

\section{ODE example}

Let's take an ODE example with some boundary conditions.


\begin{equation}
    \epsilon \frac{d^2y}{dx^2} + 2 \frac{dy}{dx} + y = 0; 0 < x < 1, 0 <
\epsilon \ll 1,
\end{equation}

and boundary conditions $y(0)=0, y(1) =1$.

The naive reduced version, $\epsilon = 0$ gives $2 \frac{dy}{dx} + y = 0$, with
general solution $y=K \exp(-\frac{1}{2} x)$

The problem here is that we can't satisfy both boundary conditions. Either the
approximation leads to $y=0$ or $y=exp(\frac 1 2 - \frac 1 2 x)$. So what does
this mean? Is either approximation good, and if so in which part of the
interval?

Here Lin and Segel show the logic of this by solving it exactly. We are gonna
jump straight into the approximation part. [Unclear if this makes sense,
considering the introduction of boundary layer etc].

Let's assume that we can that solution to the outer equation (the one we have),
approximates the exact solution everywhere but a small layer near a boundary.
Let's also assume that this boundary layer near located near $x=0$ (as opposed to near $x=1$).

We require that the outer approximation $y_O$ satisfy the boundary condition at
$x=1$. Then we have

$$2 \frac{dy_O}{dx} + y_O = 0, y_O(1)=1$$

$$y_O(x) = exp[\frac 1 2 (1-x)]$$

We let the boundary layer near $x=0$ have a thickness of order of magnitude
$\delta(\epsilon)$. This layer thickness approaches zero as $\epsilon \to 0$, so
$\delta \to 0$ as $\epsilon \to 0$.

We introduce a change of variable as a rescaling for the scale appropriate for
the boundary layer. Having a scale of order unity wouldn't be appropriate here,
which is why we introduce another scale with the following change of variable:

$$\xi = \frac x \delta$$

We now replace... (at page 292).

\chapter{TQSSA}

\section{Biological problem}

Thing and enzyme. Combines fast. QSSA two time scales. TQSSA similar.

\section{Scaling}

Scale dimensionless. Two periods. Basics of dimensionaless.

\section{Inner solution}

$0 < \epsilon \leq 1, \epsilon = \frac{t_{\epsilon}}{t_{s}}$

\section{Outer solution}

\section{Matching and uniform approximation}

\section{Applying it}

See Verdugo.

\bibliography{references}

\end{document}
