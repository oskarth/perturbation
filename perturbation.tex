\documentclass[12pt]{report}

\usepackage{hyperref}

\newcommand{\link}[2]{\href{#1}{#2}}

% \usepackage[utf8]{inputenc}
% \usepackage{mathtools}
\usepackage[parfill]{parskip} % line skip paragraphs
\linespread{1.5} % linespacing 1.5

\begin{document}

\bibliographystyle{plain}

\title{Singular Pertubation Theory and TQSSA}
\author{Oskar Thor\'{e}n}

\maketitle

\chapter{Singular perturbation theory}

\section{History and introduction}

\textit{It causeth my head to ache} -- Newton on the orbits of the moon. Three
body problem. Discovery Neptunus, but also Vulcan. Poincare and Prandtl.

Many phenomena can be modelled by ODEs, but only a subset of ODEs can be solved
exactly. We need approximate solutions that are justified in a rigorous manner.

\section{Simple regular perturbation}

Let's start with a simple quadratic equation.

\begin{equation}
  z^2 - 2z + \epsilon
\end{equation}


For small $\epsilon$, how does the solution change? The first thought we might
have is that we simply set $\epsilon$ to zero. If we do that we get two
solutions, $z_1 = 2$ and $z_2 = 0$. In this case, since we know the exact
solution to the full equationis $z = 1 \pm \sqrt{1-\epsilon}$, it's easy to see
that changing $\epsilon$ a bit only changes the solution a bit. The solutions to
the equation will be around $0$ and $2$.

When we say that $\epsilon$ is small, we mean something like $0 < \epsilon
\ll 1$. The symbol $\ll$ means that the limit of $\epsilon$ over unity
approaches $0$.

One way to do this more rigorously is to expand $\sqrt{1-\epsilon}$ part as a
Taylor series around $\epsilon = 0$. In this case, we could've used a binominal series expansion as
well.

$\sqrt{1 - \epsilon}$ = $1 - \frac 1 2 \epsilon - \frac 1 8 \epsilon^2 +
O(\epsilon^3)$

The Big-oh notation is just a way to sweep irrelevant arithmetic details under
the rug. What it's saying is that the following terms won't grow faster than on
the order of $\epsilon^2$ (which, as $\epsilon$ is close to zero, is essentially
insignificant).

Using that Taylor expansion in our original solution, and performing some basic
Big-Oh algebra, we get $z_1 = \frac 1 2 \epsilon + O(\epsilon^2)$ and $z_2 = 2 -
\frac 1 2 \epsilon + O(\epsilon^2)$. Here I'm content with the $O(\epsilon^2)$
term at the end, as more details aren't necessary for our current purposes.

What does this tell us? What've established is a way to get successively better
approximations to the solutions, given that $\epsilon$ is very small. The
reduced equation corresponds to setting $\epsilon$ to $0$. This is called
something like the 0th order perturbation. If we want the first order
perturbation, we get the solutions as seen above. You can imagine
substituting$ $\epsilon$ for a very small number, and you have some idea for how
the solutions behaves.

Let's assume we don't know exact solution to this quadratic equation. Instead
we'll assume that we can express the solution using a perturbation series. How
do we go about doing this?

We'll use

[this is great, you kind of know what's coming but not enough to write it on
your own]


\section{Simple singular perturbation}

\begin{equation}
  \epsilon z^2 - 2z + 1
\end{equation}

In this example we have $z = \frac{(1 \pm \sqrt{1-\epsilon})}{\epsilon}$. Note
that $\epsilon=0$ removes one of the roots. This is indicative of a singular
perturbation problem - we are missing something when we remove the error term.

Unlike in the last section, $z(\epsilon) = \frac 2 \epsilon + ...$, obviously a
problem here.

Perturbation series $z(\epsilon) = a_0 + a_1 \epsilon + a_2 \epsilon^2 + ... +
R^{n+1}, R^{n+1} = O(\epsilon{N+1})$

Procedure for this:

1. Substitute
2. Expand
3. Collect
4. Substitute original IC/BC
5. ...

\section{ODE example}

ODE with BC. Can't fulfil both conditions at once. So two solutions, oe inner
$O(\epsilon)$ and one other $O(1)$. Then combine (match) these to get a uniform
solution.

Lin and Segel example:

$$\epsilon \frac{d^2 y}{d x^2} + 2 \frac{dy}{dx} = 0; y(0)=0, y(1)=1, 0 <
\epsilon \ll 1.$$

If we take the reduced problem, see that the solution loses a dimension, and
can't satisfy both BCs at once. Is it still a useful approximation somewhere?

Introduce inner and outer layer. Assume outer equation is approximated by
reduced solution, except for in a thin layer of width $\epsilon$, around the
boundary layer. For simplicity, let's also assume this outer approximation
$y_o$ should satisfy the boundary condition at $x=1$ (in this example we can
figure out the exact solution, so we already know the boundary layer is near
$x=0$).

We then have eqn 23-24 from Lin and Segel.

Rescaling.

Inner equation.

Matching/intermediate region/matching.

Uniform aproximation.

\chapter{TQSSA}

\section{Biological problem}

Thing and enzyme. Combines fast. QSSA two time scales. TQSSA similar.

\section{Scaling}

Scale dimensionless. Two periods. Basics of dimensionaless.

\section{Inner solution}

$0 < \epsilon \leq 1, \epsilon = \frac{t_{\epsilon}}{t_{s}}$

\section{Outer solution}

\section{Matching and uniform approximation}

\section{Applying it}

See Verdugo.

\bibliography{references}

\end{document}
